{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JapiKredi/RAG_assignment_Research_papers/blob/main/Copy_of_together_finetune_law_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evn07vKNns1z"
      },
      "source": [
        "<center><a href=\"https://www.together.ai\" ><img src=\"https://raw.githubusercontent.com/clam004/together-examples/main/files/togetherlogo.jpg\" align=\"center\"/></a></center>\n",
        "\n",
        "[together.ai](\"https://www.together.ai\") allows you to train, finetune and deploy large language models on fast compute using 5 lines of code from your laptop, without dealing with anything having the words *cuda* in it. After you adapt these open source models for your tasks/use cases, you can download the entire model for yourself and/or serve the model on our fast inference engines. see our [docs](https://docs.together.ai/docs/fine-tuning-python) or follow along below.\n",
        "\n",
        "This python notebook is an example before and after demonstration/tutorial of using Together's finetune API to adapt a base model to a domain specific dataset in law. The dataset consists of legal related questions and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bzbT2cdNnwGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2abe4e80-400e-4eef-e92d-3a62ae5941cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15\n",
            "Collecting together\n",
            "  Downloading together-0.2.11-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m661.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from together) (3.9.1)\n",
            "Collecting pydantic<3.0.0,>=2.5.0 (from together)\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.31.0)\n",
            "Collecting sseclient-py<2.0.0,>=1.7.2 (from together)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from together) (4.66.1)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4->together) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4->together) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4->together) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4->together) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4->together) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4->together) (4.0.3)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic<3.0.0,>=2.5.0->together)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.6 (from pydantic<3.0.0,>=2.5.0->together)\n",
            "  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.6.1 (from pydantic<3.0.0,>=2.5.0->together)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2023.11.17)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.9.0->together) (8.1.7)\n",
            "Installing collected packages: sseclient-py, typing-extensions, annotated-types, pydantic-core, pydantic, together\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.14\n",
            "    Uninstalling pydantic-1.10.14:\n",
            "      Successfully uninstalled pydantic-1.10.14\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.6.0 pydantic-2.5.3 pydantic-core-2.14.6 sseclient-py-1.8.0 together-0.2.11 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "# First lets load some tools to help us manage out dataset and\n",
        "!pip install datasets\n",
        "!pip install --upgrade together"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the \"xxxx\" placeholder below, paste your Together API Key. You can get your Together API Key by signing up at [together.ai](\"https://www.together.ai\"), then going to the profile icon > Settings > API Keys.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/clam004/together-examples/main/files/SETTINGS.png\" height=350 width=250></center>\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/togethercomputer/examples/main/sample_images/UserSettings.png\" height=350 width=250></center>\n",
        "\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/clam004/together-examples/main/files/API_KEY.png\" height=250 width=350></center>\n",
        "\n",
        "First lets import our python packages and check to make sure our API Key is a 64 character alphanumeric string. Also make sure you are using the latest version of together API python library.\n"
      ],
      "metadata": {
        "id": "GeT8Vmq5P2lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WANDB_API_KEY = None # replace None with your weights and Biases API key (optional)\n",
        "TOGETHER_API_KEY = \"a497dcf59e9cc107127a6be8ab95e6b9695c2ab45ca32733e7f9a18503c95b91\" # replace \"xxxx\" with your together API key (needed but easy)"
      ],
      "metadata": {
        "id": "trPCsf4FfF3Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GguIz1rPn3BV",
        "outputId": "52125ca9-ff07-456a-8167-7b26437f3bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using TOGETHER_API_KEY ending in 5b91\n",
            "together.VERSION 0.2.11\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import together\n",
        "\n",
        "# check to make sure you have the right key, ie: xxxx.....c04c\n",
        "print(f\"using TOGETHER_API_KEY ending in {TOGETHER_API_KEY[-4:]}\")\n",
        "print(\"together.VERSION\", together.VERSION)\n",
        "\n",
        "together.api_key = TOGETHER_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go to https://docs.together.ai/docs/fine-tuning-models to see a full list of our current base models available for finetuning"
      ],
      "metadata": {
        "id": "UbEcD6khThag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets use our base model to see how it works before we finetune it\n",
        "\n",
        "base_model_name = \"togethercomputer/Llama-2-7B-32K-Instruct\"\n",
        "#base_model_name = \"togethercomputer/llama-2-7b-chat\""
      ],
      "metadata": {
        "id": "KWopmY-MTRwe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See [fine-tuning-task-specific-sequences](https://docs.together.ai/docs/fine-tuning-task-specific-sequences) for a full description of how to template/format/structure your finetuning data for your use case.\n",
        "\n",
        "The TL;DR is that you can teach your model how to follow a new set of special symbols and grammar, or you can build on top of the patte you can give your model the background knowledge, context or identity in the system prompt `<s>[INST] <<SYS>> {system_prompt} <</SYS>>` and then train it to be consistent with the system prompt instructions as it does multi-turn chat by concatenating repeated ` {user_msg} [/INST] {model_answer} </s>` utterance pairs to the right end of a growing sequence of dialog history. The interface you build will have to use these special sequences like `</s>` and `[/INST]` to extract out the model's responses and input back into the model the growing history of conversational turns. Lets first see how the the model behaves with one method of formatting text, the Llama-2 style."
      ],
      "metadata": {
        "id": "eJkFuQEET9zm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "YR7L3VjDqwGW",
        "outputId": "55082fac-42c1-4081-a398-13db2c701af5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] <<SYS>> you are a helpful legal assistant <</SYS>> Analyze and explain the legal reasoning behind the judgment in the given case.\\n\\nCentral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278 [/INST]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "test_chat_prompt = \"<s>[INST] <<SYS>> you are a helpful legal assistant <</SYS>> Analyze and explain the legal reasoning behind the judgment in the given case.\\n\\nCentral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278 [/INST]\"\n",
        "test_chat_prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(base_model_name)\n",
        "\n",
        "output = together.Complete.create(\n",
        "  prompt = test_chat_prompt,\n",
        "  model = base_model_name,\n",
        "  max_tokens = 256,\n",
        "  temperature = 0.6,\n",
        "  top_k = 90,\n",
        "  top_p = 0.8,\n",
        "  repetition_penalty = 1.1,\n",
        "  stop = ['</s>', '[/INST]']\n",
        ")\n",
        "\n",
        "# print generated text\n",
        "print(output['prompt'][0]+\" -> \"+output['output']['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDHfcuFoTyaC",
        "outputId": "5e998dad-e4a6-44bf-cdb4-e93ac716ed70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "togethercomputer/Llama-2-7B-32K-Instruct\n",
            "<s>[INST] <<SYS>> you are a helpful legal assistant <</SYS>> Analyze and explain the legal reasoning behind the judgment in the given case.\n",
            "\n",
            "Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278 [/INST] -> \n",
            "\n",
            "In Central Inland Water Transport Corporation Ltd. v. Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278, the Supreme Court held that where there is an arbitration agreement between the parties, the court cannot interfere with the arbitrator's award unless it is shown to be perverse or manifestly unjust. The court must defer to the arbitrator's decision and give it due regard unless there is evidence of fraud, bias, or other improper conduct on the part of the arbitrator.\n",
            "\n",
            "The court in this case was considering whether an order passed by an arbitrator could be set aside on the ground of public policy. The court held that public policy can only be invoked if the arbitrator's award violates fundamental principles of justice or morality, or if it is contrary to the interests of society as a whole.\n",
            "\n",
            "The court also emphasized that when a party objects to an arbitrator's award on the ground of public policy, it must show that the award is so unfair or unreasonable that it would be against public policy to enforce it. The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets take a look at structure of the data we will be using\n",
        "\n",
        "\n",
        "`\n",
        "<s>[INST] <<SYS>> you are a helpful legal assistant <</SYS>> Analyze and explain the legal reasoning behind the judgment in the given case.:Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278\n",
        "[/INST]\n",
        "The Supreme Court in this case applied a broad interpretation of the term 'State' under Article 12 of the Constitution. The court reasoned that a government company undertaking public functions qualifies as 'State' based on factors like government control, public importance of activities etc. This interpretation was based on previous decisions that have defined 'State' under Article 12 broadly to include various agencies and instrumentalities beyond just statutory bodies. The court also applied the principle that unreasonable and arbitrary contractual terms can be struck down under Article 14 of the Constitution. The court found that Rule 9(i) of the service rules, which allowed for termination of service without reason, conferred unfettered power to terminate employment without hearing. This was deemed arbitrary and violative of principles of natural justice and right to equality under Article 14. Furthermore, the court held that the right to life and livelihood under Article 21 is affected by arbitrary termination of employment. The court reasoned that the right to livelihood is an integral part of the right to life, and any arbitrary action that affects a person's livelihood would be a violation of Article 21.In conclusion, the court's legal reasoning was based on a broad interpretation of the term 'State', the application of the principle of equality and natural justice under Article 14, and the protection of the right to life and livelihood under Article 21. </s>\n",
        "`\n"
      ],
      "metadata": {
        "id": "qHG97ElMbL0s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411,
          "referenced_widgets": [
            "b34f5635fd58446ea256f3ac3762aae4",
            "15be3b7c0b7c4fe598aa2e8b29fdbc7e",
            "8e3b020a5dae49b6836dd3c54c66b493",
            "3e7a3e1d52a04da4aa0612823ee8d57e",
            "d43f30e636d74cc99d0d3c668082713d",
            "83d91f1696ab4ed096284b96b71c25a9",
            "7b76294077204a6c899606d523428617",
            "9373df12e9dd40d58de28865a9827c31",
            "fc3365e4be534f8aaca8c2a2f957e7f9",
            "4b7a2d28bfb24a81ae2b6b6f2379df19",
            "90dc8b1b367e478482f4856162129cb9",
            "0145b91b86bc4fe78ebe72785ed7758c",
            "a98b2ff6aa0946d3877c1e038b62772d",
            "79db878ae0134335b628bc56083f8fcb",
            "5544c1a8b12b412192e5da71c2291b7c",
            "b9fd9c839987419b83314bec632ed950",
            "c7d554ed06004af59f06c32dae12fa83",
            "80718bc641884430b62163e4d540477e",
            "a1eb0061dd2d4b39a512883b50d46d13",
            "7ebea315733d42a6a90c25497ce8cdb5",
            "1ee1bb84188d4cfcbedf092ba1b6f3ae",
            "c5a7983ad0f74e9e85d63d1af264f059",
            "58ca340872fb4f28843b6ac478104ad4",
            "6ad1fc577f734daf902eea84ecdd2909",
            "ab1e8c19e549426d8b4812061659a69b",
            "42f1cfe6227f45d0b0339a64724c20d1",
            "1548c4f87e5c4a6c82bde0f2dce9afd0",
            "4cad8c3d5ab448a8865998908c18485d",
            "906251d9b2ef42a3863030ccbd1038cb",
            "5acde7641f924036ab2e9e3c5744f884",
            "2875429fb6644e6eaa172d51313b26c4",
            "96e13654b5c341308d3ae3b86edee1fd",
            "049ff9df15da41969c463515dba07908"
          ]
        },
        "id": "G4nobWYGoOYx",
        "outputId": "8ddd3209-90ee-4b24-fea2-8e126b2ebe90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b34f5635fd58446ea256f3ac3762aae4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0145b91b86bc4fe78ebe72785ed7758c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58ca340872fb4f28843b6ac478104ad4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['instruction', 'input', 'output', 'prompt', 'text'],\n",
            "        num_rows: 4394\n",
            "    })\n",
            "})\n",
            "--------------------------------------------------\n",
            "{'instruction': 'Analyze and explain the legal reasoning behind the judgment in the given case.', 'input': 'Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278', 'output': \"The Supreme Court in this case applied a broad interpretation of the term 'State' under Article 12 of the Constitution. The court reasoned that a government company undertaking public functions qualifies as 'State' based on factors like government control, public importance of activities etc. This interpretation was based on previous decisions that have defined 'State' under Article 12 broadly to include various agencies and instrumentalities beyond just statutory bodies. The court also applied the principle that unreasonable and arbitrary contractual terms can be struck down under Article 14 of the Constitution. The court found that Rule 9(i) of the service rules, which allowed for termination of service without reason, conferred unfettered power to terminate employment without hearing. This was deemed arbitrary and violative of principles of natural justice and right to equality under Article 14. Furthermore, the court held that the right to life and livelihood under Article 21 is affected by arbitrary termination of employment. The court reasoned that the right to livelihood is an integral part of the right to life, and any arbitrary action that affects a person's livelihood would be a violation of Article 21.In conclusion, the court's legal reasoning was based on a broad interpretation of the term 'State', the application of the principle of equality and natural justice under Article 14, and the protection of the right to life and livelihood under Article 21.\", 'prompt': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnalyze and explain the legal reasoning behind the judgment in the given case.\\n\\n### Input:\\nCentral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278\\n\\n### Response:', 'text': \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnalyze and explain the legal reasoning behind the judgment in the given case.\\n\\n### Input:\\nCentral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278\\n\\n### Response:The Supreme Court in this case applied a broad interpretation of the term 'State' under Article 12 of the Constitution. The court reasoned that a government company undertaking public functions qualifies as 'State' based on factors like government control, public importance of activities etc. This interpretation was based on previous decisions that have defined 'State' under Article 12 broadly to include various agencies and instrumentalities beyond just statutory bodies. The court also applied the principle that unreasonable and arbitrary contractual terms can be struck down under Article 14 of the Constitution. The court found that Rule 9(i) of the service rules, which allowed for termination of service without reason, conferred unfettered power to terminate employment without hearing. This was deemed arbitrary and violative of principles of natural justice and right to equality under Article 14. Furthermore, the court held that the right to life and livelihood under Article 21 is affected by arbitrary termination of employment. The court reasoned that the right to livelihood is an integral part of the right to life, and any arbitrary action that affects a person's livelihood would be a violation of Article 21.In conclusion, the court's legal reasoning was based on a broad interpretation of the term 'State', the application of the principle of equality and natural justice under Article 14, and the protection of the right to life and livelihood under Article 21.\"}\n",
            "--------------------------------------------------\n",
            "{'instruction': 'Identify and summarize the key legal issues in the provided case.', 'input': 'Case Citation: Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278. The case revolves around the termination of employment of the respondents by the appellant without assigning any reason by invoking Rule 9(i) of the service rules. The respondents challenged the termination orders and the validity of Rule 9(i) in the High Court under Article 226. The Division Bench of the High Court struck down Rule 9(i) as arbitrary and violative of Article 14. The appellant filed appeals in the Supreme Court against the High Court judgment.', 'output': \"The key legal issues in the case Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr. are as follows: 1. The first issue is whether a government company falls under the definition of 'State' as per Article 12 of the Indian Constitution. This is important as the constitutional protections against arbitrary state action apply to 'State' entities. 2. The second issue is the constitutional validity of Rule 9(i) that allows termination of service without reason. The respondents challenged this rule as arbitrary and violative of the right to equality under Article 14 of the Constitution. 3. The third issue is the application of principles of natural justice and constitutional protections in contractual relationships, particularly in employment contracts of state entities. 4. The fourth issue is the impact of arbitrary termination of employment on the right to life and livelihood under Article 21 of the Constitution. 5. The final issue is the scope of judicial review of state action in contractual matters, particularly in the context of employment relationships.\", 'prompt': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIdentify and summarize the key legal issues in the provided case.\\n\\n### Input:\\nCase Citation: Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278. The case revolves around the termination of employment of the respondents by the appellant without assigning any reason by invoking Rule 9(i) of the service rules. The respondents challenged the termination orders and the validity of Rule 9(i) in the High Court under Article 226. The Division Bench of the High Court struck down Rule 9(i) as arbitrary and violative of Article 14. The appellant filed appeals in the Supreme Court against the High Court judgment.\\n\\n### Response:', 'text': \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIdentify and summarize the key legal issues in the provided case.\\n\\n### Input:\\nCase Citation: Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278. The case revolves around the termination of employment of the respondents by the appellant without assigning any reason by invoking Rule 9(i) of the service rules. The respondents challenged the termination orders and the validity of Rule 9(i) in the High Court under Article 226. The Division Bench of the High Court struck down Rule 9(i) as arbitrary and violative of Article 14. The appellant filed appeals in the Supreme Court against the High Court judgment.\\n\\n### Response:The key legal issues in the case Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr. are as follows: 1. The first issue is whether a government company falls under the definition of 'State' as per Article 12 of the Indian Constitution. This is important as the constitutional protections against arbitrary state action apply to 'State' entities. 2. The second issue is the constitutional validity of Rule 9(i) that allows termination of service without reason. The respondents challenged this rule as arbitrary and violative of the right to equality under Article 14 of the Constitution. 3. The third issue is the application of principles of natural justice and constitutional protections in contractual relationships, particularly in employment contracts of state entities. 4. The fourth issue is the impact of arbitrary termination of employment on the right to life and livelihood under Article 21 of the Constitution. 5. The final issue is the scope of judicial review of state action in contractual matters, particularly in the context of employment relationships.\"}\n"
          ]
        }
      ],
      "source": [
        "# lets load and take a look at two samples from our 4394 sample dataset\n",
        "legal_dataset = load_dataset(\"nisaar/LLAMA2_Legal_Dataset_4.4k_Instructions\")\n",
        "\n",
        "print(legal_dataset)\n",
        "print(\"-\"*50)\n",
        "print(legal_dataset['train'][0])\n",
        "print(\"-\"*50)\n",
        "print(legal_dataset['train'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "IAbGwo3hoseO",
        "outputId": "e6d13e7a-ebda-4c95-952c-e91906a0b20f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] <<SYS>> You are a good robot <</SYS>> hi robot [/INST] hello human </s> are you good? [/INST] yes im good </s> are you bad? [/INST] no, im good </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def format_to_llama2_chat(system_prompt, user_model_chat_list):\n",
        "\n",
        "    \"\"\" this function follows from\n",
        "    https://docs.together.ai/docs/fine-tuning-task-specific-sequences\n",
        "\n",
        "    It converts this legal dataset into the Llama-2 prompting structure\n",
        "\n",
        "    Args:\n",
        "      system_prompt (str): instructions from you the developer to the AI\n",
        "      user_model_chat_list (List[Tuple[str,str]]): a list of tuples,\n",
        "        where each tuple is a pair or exchange of string utterances, the first by the user,\n",
        "        the second by the AI. The earlier exchanges are on the left, meaning time\n",
        "        runs left to right.\n",
        "    Returns:\n",
        "      growing_prompt (str): the concatenated sequence starting with system_prompt and\n",
        "        alternating utterances between the user and AI with the last AI utternance on the right.\n",
        "    \"\"\"\n",
        "\n",
        "    growing_prompt = f\"\"\"<s>[INST] <<SYS>> {system_prompt} <</SYS>>\"\"\"\n",
        "\n",
        "    for user_msg, model_answer in user_model_chat_list:\n",
        "        growing_prompt += f\"\"\" {user_msg} [/INST] {model_answer} </s>\"\"\"\n",
        "\n",
        "    return growing_prompt\n",
        "\n",
        "format_to_llama2_chat(\n",
        "    \"You are a good robot\",\n",
        "    [(\"hi robot\", \"hello human\"),(\"are you good?\", \"yes im good\"),(\"are you bad?\", \"no, im good\")]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y94pU2mDpsSz",
        "outputId": "9a5034ff-c761-4e34-d77b-21678310951d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4394\n",
            "{'text': \"<s>[INST] <<SYS>> you are a helpful legal assistant <</SYS>> Analyze and explain the legal reasoning behind the judgment in the given case. Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278 [/INST] The Supreme Court in this case applied a broad interpretation of the term 'State' under Article 12 of the Constitution. The court reasoned that a government company undertaking public functions qualifies as 'State' based on factors like government control, public importance of activities etc. This interpretation was based on previous decisions that have defined 'State' under Article 12 broadly to include various agencies and instrumentalities beyond just statutory bodies. The court also applied the principle that unreasonable and arbitrary contractual terms can be struck down under Article 14 of the Constitution. The court found that Rule 9(i) of the service rules, which allowed for termination of service without reason, conferred unfettered power to terminate employment without hearing. This was deemed arbitrary and violative of principles of natural justice and right to equality under Article 14. Furthermore, the court held that the right to life and livelihood under Article 21 is affected by arbitrary termination of employment. The court reasoned that the right to livelihood is an integral part of the right to life, and any arbitrary action that affects a person's livelihood would be a violation of Article 21.In conclusion, the court's legal reasoning was based on a broad interpretation of the term 'State', the application of the principle of equality and natural justice under Article 14, and the protection of the right to life and livelihood under Article 21. </s>\"}\n"
          ]
        }
      ],
      "source": [
        "data_list = []\n",
        "\n",
        "for sample in legal_dataset['train']:\n",
        "\n",
        "    instruction_input_separator = random.choice([\":\", \": \", \"\\n\", \"\\n\\n\", \" \"])\n",
        "    input = sample['input'] if sample['input'] is not None else \"\"\n",
        "    instruction = sample['instruction'] if sample['instruction'] is not None else \"\"\n",
        "\n",
        "    training_sequence = format_to_llama2_chat(\n",
        "        \"you are a helpful legal assistant\",\n",
        "        [(instruction+instruction_input_separator+input,sample['output'])]\n",
        "    )\n",
        "\n",
        "    data_list.append({\n",
        "        \"text\":training_sequence\n",
        "    })\n",
        "\n",
        "print(len(data_list))\n",
        "print(data_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpiHp384pxKO",
        "outputId": "b5c343da-265d-4d03-936c-210011e807a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 4394 records to legal_dataset.jsonl\n"
          ]
        }
      ],
      "source": [
        "# save the reformatted dataset locally\n",
        "together.Files.save_jsonl(data_list, \"legal_dataset.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM-Miyytp3bt",
        "outputId": "b42902e0-8842-46d8-cdf8-05030a4e0e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'is_check_passed': True, 'model_special_tokens': 'we are not yet checking end of sentence tokens for this model', 'file_present': 'File found', 'file_size': 'File size 0.007 GB', 'num_samples': 4394}\n"
          ]
        }
      ],
      "source": [
        "# check your data with your base model prompting type before uploading\n",
        "resp = together.Files.check(file=\"legal_dataset.jsonl\")\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = together.Files.list()\n",
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tykt9VcsSwo",
        "outputId": "2aaf4f36-befa-462d-ae9b-60635fca1630"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': [], 'object': 'list'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "X6jO__J3p6cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567544d6-dcd2-4922-de92-af9401cf9e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading legal_dataset.jsonl: 100%|██████████| 6.96M/6.96M [00:03<00:00, 2.01MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'filename': 'legal_dataset.jsonl', 'id': 'file-d19ded63-4ac6-4f9d-9732-10cc6a2bdd50', 'object': 'file', 'report_dict': {'is_check_passed': True, 'model_special_tokens': 'we are not yet checking end of sentence tokens for this model', 'file_present': 'File found', 'file_size': 'File size 0.007 GB', 'num_samples': 4394}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# upload your dataset file to together and save the file-id, youll need it to start your finetuning run\n",
        "file_resp = together.Files.upload(file=\"legal_dataset.jsonl\")\n",
        "file_id = file_resp[\"id\"]\n",
        "print(file_resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output: ```{'filename': 'legal_dataset.jsonl', 'id': 'file-69649a68-6a36-41ad-8420-1750e99c26a7', 'object': 'file', 'report_dict': {'is_check_passed': True, 'model_special_tokens': 'we are not yet checking end of sentence tokens for this model', 'file_present': 'File found', 'file_size': 'File siz```\n",
        "\n",
        "### Finetuning the base model on the new dataset to create the new finetuned model\n",
        "\n",
        "depending on the size of the model and dataset this could take a few minutes to hours"
      ],
      "metadata": {
        "id": "nkQL1NEoZw5F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj-36LXip9tA",
        "outputId": "381c25c9-95b2-477c-ee77-4c03952277a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'training_file': 'file-d19ded63-4ac6-4f9d-9732-10cc6a2bdd50', 'validation_file': '', 'model_output_name': 'jasper.bongers@yahoo.com/Llama-2-7B-32K-Instruct-law-2024-01-28-12-11-54', 'model_output_path': 's3://together-dev/finetune/65b6294d5573b6768acf8cf7/jasper.bongers@yahoo.com/Llama-2-7B-32K-Instruct-law-2024-01-28-12-11-54/ft-c417d73c-f233-4f27-994f-6f4ee6f5f165', 'Suffix': 'law', 'model': 'togethercomputer/Llama-2-7B-32K-Instruct', 'n_epochs': 2, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 5e-05, 'user_id': '65b6294d5573b6768acf8cf7', 'lora': False, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0, 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2024-01-28T12:11:54.451Z', 'updated_at': '2024-01-28T12:11:54.451Z', 'status': 'pending', 'owner_address': '0x3280fb629a1e4ce39da76c58cb4850efcd5db1a0', 'id': 'ft-c417d73c-f233-4f27-994f-6f4ee6f5f165', 'job_id': '', 'token_count': 0, 'param_count': 0, 'total_price': 0, 'epochs_completed': 0, 'events': [{'object': 'fine-tune-event', 'created_at': '2024-01-28T12:11:54.451Z', 'level': '', 'message': 'Fine tune request created', 'type': 'JOB_PENDING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': ''}], 'queue_depth': 0, 'wandb_key': '', 'wandb_project_name': '', 'wandb_url': '', 'enable_checkpoints': False, 'internal_flags': '', 'UsedModelName': '', 'TrainingFileNumLines': 0, 'TrainingFileSize': 7296596, 'job_stats': {'FtUserTime': '', 'FtSysTime': '', 'FtMaxRss': 0, 'FtMinPgFlt': 0, 'FtMajPgFlt': 0, 'FtInBlock': 0, 'FtOutBlock': 0, 'FtNvCsw': 0, 'FtNivCsw': 0}}\n"
          ]
        }
      ],
      "source": [
        "# Submit your finetune job\n",
        "ft_resp = together.Finetune.create(\n",
        "  training_file = file_id ,\n",
        "  model = base_model_name,\n",
        "  n_epochs = 2,\n",
        "  batch_size = 4,\n",
        "  n_checkpoints = 1,\n",
        "  learning_rate = 5e-5,\n",
        "  wandb_api_key = WANDB_API_KEY,\n",
        "  #estimate_price = True,\n",
        "  suffix = 'law',\n",
        ")\n",
        "\n",
        "fine_tune_id = ft_resp['id']\n",
        "print(ft_resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "```{'training_file': 'file-69649a68-6a36-41ad-8420-1750e99c26a7', 'model_output_name': 'carson/llama-2-7b-chat-law-2023-09-22-20-37-12', 'model_output_path': 's3://together-dev/finetune/64c4302a5cb247a0c80a3ddb/carson/llama-2-7b-chat-law-2023-09-22-20-37-12/ft-2aaecf7b-ff6f-4341-813a-45d84ae2b1bf', 'Suffix': 'law', 'model': 'togethercomputer/llama-2-7b-chat', 'n_epochs': 2, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 0.0001, 'user_id': '64c4302a5cb247a0c80a3ddb', 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2023-09-22T20:37:12.007Z', 'updated_at': '2023-09-22T20:37:12.007Z', 'status': 'pending', 'owner_address': '0xef5286fc0a1ac5bc4d4221cf3d51f1d97c45eaf7', 'id': 'ft-2aaecf7b-ff6f-4341-813a-45d84ae2b1bf', 'job_id': '', 'token_count': 0, 'param_count': 0, 'total_price': 0, 'epochs_completed': 0, 'events': [{'object': 'fine-tune-event', 'created_at': '2023-09-22T20:37:12.007Z', 'level': '', 'message': 'Fine tune request created', 'type': 'JOB_PENDING', 'param_count': 0, 'token_count': 0, 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': ''}], 'queue_depth': 0, 'wandb_key': '', 'wandb_project_name': '', 'enable_checkpoints': False}```"
      ],
      "metadata": {
        "id": "HUCVE-vHZ5y2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjUfusXGqD2d",
        "outputId": "8e039866-2781-4464-ada1-9d0261b83357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'training_file': 'file-d19ded63-4ac6-4f9d-9732-10cc6a2bdd50', 'validation_file': '', 'model_output_name': 'jasper.bongers@yahoo.com/Llama-2-7B-32K-Instruct-law-2024-01-28-12-11-54', 'model_output_path': 's3://together-dev/finetune/65b6294d5573b6768acf8cf7/jasper.bongers@yahoo.com/Llama-2-7B-32K-Instruct-law-2024-01-28-12-11-54/ft-c417d73c-f233-4f27-994f-6f4ee6f5f165', 'Suffix': 'law', 'model': 'togethercomputer/Llama-2-7B-32K-Instruct', 'n_epochs': 2, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 5e-05, 'user_id': '65b6294d5573b6768acf8cf7', 'lora': False, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0, 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2024-01-28T12:11:54.451Z', 'updated_at': '2024-01-28T12:11:58.329Z', 'status': 'running', 'owner_address': '0x3280fb629a1e4ce39da76c58cb4850efcd5db1a0', 'id': 'ft-c417d73c-f233-4f27-994f-6f4ee6f5f165', 'job_id': '11938', 'token_count': 0, 'param_count': 0, 'total_price': 0, 'epochs_completed': 0, 'events': [{'object': 'fine-tune-event', 'created_at': '2024-01-28T12:11:54.451Z', 'level': '', 'message': 'Fine tune request created', 'type': 'JOB_PENDING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': ''}, {'object': 'fine-tune-event', 'created_at': '2024-01-28T12:11:57Z', 'level': 'Info', 'message': 'Job started at Sun Jan 28 04:11:57 PST 2024', 'type': 'JOB_START', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-322962454238243142'}], 'queue_depth': 0, 'wandb_key': '', 'wandb_project_name': '', 'wandb_url': '', 'enable_checkpoints': False, 'internal_flags': '', 'UsedModelName': '', 'TrainingFileNumLines': 0, 'TrainingFileSize': 7296596, 'job_stats': {'FtUserTime': '', 'FtSysTime': '', 'FtMaxRss': 0, 'FtMinPgFlt': 0, 'FtMajPgFlt': 0, 'FtInBlock': 0, 'FtOutBlock': 0, 'FtNvCsw': 0, 'FtNivCsw': 0}}\n",
            "--------------------------------------------------\n",
            "running\n",
            "False\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# run this from time to time to check on the status of your job\n",
        "print(together.Finetune.retrieve(fine_tune_id=fine_tune_id)) # retrieves information on finetune event\n",
        "print(\"-\"*50)\n",
        "print(together.Finetune.get_job_status(fine_tune_id=fine_tune_id)) # pending, running, completed\n",
        "print(together.Finetune.is_final_model_available(fine_tune_id=fine_tune_id)) # True, False\n",
        "print(together.Finetune.get_checkpoints(fine_tune_id=fine_tune_id)) # list of checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monitor your training/finetuning progress using weights and biases. Below we verify that our model is learning and our training loss is decreasing.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/clam004/together-examples/main/files/wandb.jpg\" height=300 width=600> </center>\n"
      ],
      "metadata": {
        "id": "mV1CK0C3hWQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(together.Finetune.get_job_status(fine_tune_id=fine_tune_id)) # pending, running, completed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHJEQ7ywg1va",
        "outputId": "be3415b9-1864-480e-ae1c-a390d6d474fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_job_status will transition from `pending`, `queued`, `running`, to `complete`.\n",
        "\n",
        "when the job is finished, you should see:\n",
        "```\n",
        "{'training_file': 'file-69649a68-6a36-41ad-8420-1750e99c26a7', 'model_output_name': 'carson/llama-2-7b-chat-law-2023-09-22-20-37-12', 'model_output_path': 's3://together-dev/finetune/64c4302a5cb247a0c80a3ddb/carson/llama-2-7b-chat-law-2023-09-22-20-37-12/ft-2aaecf7b-ff6f-4341-813a-45d84ae2b1bf-2023-09-22-13-47-25', 'Suffix': 'law', 'model': 'togethercomputer/llama-2-7b-chat', 'n_epochs': 2, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 0.0001, 'user_id': '64c4302a5cb247a0c80a3ddb', 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2023-09-22T20:37:12.007Z', 'updated_at': '2023-09-22T20:52:52.675Z', 'status': 'completed', 'owner_address': '0xef5286fc0a1ac5bc4d4221cf3d51f1d97c45eaf7', 'id': 'ft-2aaecf7b-ff6f-4341-813a-45d84ae2b1bf', 'job_id': '1509', 'token_count': 1676524, 'param_count': 6738415616, 'total_price': 5000000000, 'epochs_completed': 2, 'events': [{'object': 'fine-tune-event', 'created_at': '2023-09-22T20:37:12.007Z .....\n",
        "\n",
        "completed\n",
        "\n",
        "True\n",
        "[]\n",
        "```"
      ],
      "metadata": {
        "id": "YC0_BePQaJx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The name of your finetuned model will show up in your list of models, but before you can start using it, you need to start it and it needs to finish deploying.\n",
        "\n",
        "You can also find the name of your new model, start it and stop it, at https://api.together.xyz/playground\n",
        "\n",
        "under `Models` > `My Model Instances`\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/clam004/together-examples/main/files/mymodels.jpg\" height=300 width=600></center>"
      ],
      "metadata": {
        "id": "yufmqUI-azNy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xpPklOK-q1DM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8205e8bb-2ed1-4041-e137-bcc25075553a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128 models available\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# replace this name with the name of your newly finetuned model\n",
        "new_model_name = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
        "\n",
        "model_list = together.Models.list()\n",
        "\n",
        "print(f\"{len(model_list)} models available\")\n",
        "\n",
        "available_model_names = [model_dict['name'] for model_dict in model_list]\n",
        "\n",
        "new_model_name in available_model_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "Ct-R3HF2wP4h",
        "outputId": "645478c4-7d78-4f0d-d115-80bbd2cd29fc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "404 Client Error: Not Found for url: https://api.together.xyz/instances/start?model=mistralai/Mixtral-8x7B-Instruct-v0.1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-81798788a9e9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# deploy your newly finetuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/together/models.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mtogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"start?model={model}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         )\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_post_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/together/utils.py\u001b[0m in \u001b[0;36mcreate_post_request\u001b[0;34m(url, headers, json, stream, check_auth, api_key)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mtogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mresponse_status_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/together/utils.py\u001b[0m in \u001b[0;36mresponse_status_exception\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid authentication credentials\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.together.xyz/instances/start?model=mistralai/Mixtral-8x7B-Instruct-v0.1"
          ]
        }
      ],
      "source": [
        "# deploy your newly finetuned model\n",
        "together.Models.start(new_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "GTeqwrSwspWs",
        "outputId": "391dcf92-4a98-425e-c9d1-5dec5a5e830f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "404 Client Error: Not Found for url: https://api.together.xyz/models/info?name=togethercomputer/llama-2-7b-chat",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-677eb8bf6bcc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check if your model is finished deploying, if this returns {\"ready\": true}, you model is ready for inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/together/models.py\u001b[0m in \u001b[0;36mready\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mready_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/info?name=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_get_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mready_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/together/utils.py\u001b[0m in \u001b[0;36mcreate_get_request\u001b[0;34m(url, headers, json, stream, check_auth)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mtogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mresponse_status_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/together/utils.py\u001b[0m in \u001b[0;36mresponse_status_exception\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid authentication credentials\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.together.xyz/models/info?name=togethercomputer/llama-2-7b-chat"
          ]
        }
      ],
      "source": [
        "# check if your model is finished deploying, if this returns {\"ready\": true}, you model is ready for inference\n",
        "together.Models.ready(new_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q4wXuwruwVRa"
      },
      "outputs": [],
      "source": [
        "# use the inference API to generate text / create completion / chat\n",
        "print(new_model_name)\n",
        "\n",
        "output = together.Complete.create(\n",
        "  prompt = test_chat_prompt,\n",
        "  model = new_model_name,\n",
        "  max_tokens = 256,\n",
        "  temperature = 0.6,\n",
        "  top_k = 90,\n",
        "  top_p = 0.8,\n",
        "  repetition_penalty = 1.1,\n",
        "  stop = ['</s>']\n",
        ")\n",
        "\n",
        "# print generated text\n",
        "print(output['prompt'][0]+\" -> \"+output['output']['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQwlh60s2x-6"
      },
      "source": [
        "#### Example input separated from generated output by the ` -> ` sequence:\n",
        "\n",
        "\n",
        "`<s>[INST] <<SYS>> you are a helpful legal assistant <</SYS>> Analyze and explain the legal reasoning behind the judgment in the given case.\\n\\nCentral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278 [/INST]`\n",
        "\n",
        " ` -> `\n",
        "\n",
        " `The Supreme Court's decision in Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr. was based on several key legal principles and reasoning. Firstly, the court held that Article 14 of the Indian Constitution, which guarantees the right to equality, can apply to contractual terms between State entities and private parties if found arbitrary. This means that even though the employees were not government servants under the definition provided under Article 12, their service conditions could still be subject to constitutional scrutiny. Secondly, the court emphasized that Article 14 does not require proof of malice or mala fides for a termination to be deemed arbitrary. Instead, it is enough to show that the termination violates the principle of reasonableness and non-arbitrariness. Thirdly, the court rejected the doctrine of 'State instrumentality' as a valid defense against writ jurisdiction, stating that an entity will be considered 'State' only if there is deep and pervasive governmental control in its functioning and financing. Lastly, the court clarified that the right to livelihood under Article 21 is affected by arbitrary termination of employment. Therefore, .....`\n",
        "  `</s>`\n",
        "\n",
        "##### *the stop token is `</s>`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS3F7CQ62voL",
        "outputId": "539f5fa0-a912-485f-db42-c00c2aa1c79d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True, 'wasAlreadyDisabled': True}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# stop your model and you will no longer be paying for it\n",
        "together.Models.stop(new_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ynmQg1nYFSv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b34f5635fd58446ea256f3ac3762aae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15be3b7c0b7c4fe598aa2e8b29fdbc7e",
              "IPY_MODEL_8e3b020a5dae49b6836dd3c54c66b493",
              "IPY_MODEL_3e7a3e1d52a04da4aa0612823ee8d57e"
            ],
            "layout": "IPY_MODEL_d43f30e636d74cc99d0d3c668082713d"
          }
        },
        "15be3b7c0b7c4fe598aa2e8b29fdbc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d91f1696ab4ed096284b96b71c25a9",
            "placeholder": "​",
            "style": "IPY_MODEL_7b76294077204a6c899606d523428617",
            "value": "Downloading readme: 100%"
          }
        },
        "8e3b020a5dae49b6836dd3c54c66b493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9373df12e9dd40d58de28865a9827c31",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc3365e4be534f8aaca8c2a2f957e7f9",
            "value": 28
          }
        },
        "3e7a3e1d52a04da4aa0612823ee8d57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b7a2d28bfb24a81ae2b6b6f2379df19",
            "placeholder": "​",
            "style": "IPY_MODEL_90dc8b1b367e478482f4856162129cb9",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.31kB/s]"
          }
        },
        "d43f30e636d74cc99d0d3c668082713d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83d91f1696ab4ed096284b96b71c25a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b76294077204a6c899606d523428617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9373df12e9dd40d58de28865a9827c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3365e4be534f8aaca8c2a2f957e7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b7a2d28bfb24a81ae2b6b6f2379df19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90dc8b1b367e478482f4856162129cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0145b91b86bc4fe78ebe72785ed7758c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a98b2ff6aa0946d3877c1e038b62772d",
              "IPY_MODEL_79db878ae0134335b628bc56083f8fcb",
              "IPY_MODEL_5544c1a8b12b412192e5da71c2291b7c"
            ],
            "layout": "IPY_MODEL_b9fd9c839987419b83314bec632ed950"
          }
        },
        "a98b2ff6aa0946d3877c1e038b62772d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d554ed06004af59f06c32dae12fa83",
            "placeholder": "​",
            "style": "IPY_MODEL_80718bc641884430b62163e4d540477e",
            "value": "Downloading data: 100%"
          }
        },
        "79db878ae0134335b628bc56083f8fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1eb0061dd2d4b39a512883b50d46d13",
            "max": 16933503,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ebea315733d42a6a90c25497ce8cdb5",
            "value": 16933503
          }
        },
        "5544c1a8b12b412192e5da71c2291b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee1bb84188d4cfcbedf092ba1b6f3ae",
            "placeholder": "​",
            "style": "IPY_MODEL_c5a7983ad0f74e9e85d63d1af264f059",
            "value": " 16.9M/16.9M [00:08&lt;00:00, 1.56MB/s]"
          }
        },
        "b9fd9c839987419b83314bec632ed950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d554ed06004af59f06c32dae12fa83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80718bc641884430b62163e4d540477e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1eb0061dd2d4b39a512883b50d46d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ebea315733d42a6a90c25497ce8cdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ee1bb84188d4cfcbedf092ba1b6f3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a7983ad0f74e9e85d63d1af264f059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58ca340872fb4f28843b6ac478104ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ad1fc577f734daf902eea84ecdd2909",
              "IPY_MODEL_ab1e8c19e549426d8b4812061659a69b",
              "IPY_MODEL_42f1cfe6227f45d0b0339a64724c20d1"
            ],
            "layout": "IPY_MODEL_1548c4f87e5c4a6c82bde0f2dce9afd0"
          }
        },
        "6ad1fc577f734daf902eea84ecdd2909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cad8c3d5ab448a8865998908c18485d",
            "placeholder": "​",
            "style": "IPY_MODEL_906251d9b2ef42a3863030ccbd1038cb",
            "value": "Generating train split: "
          }
        },
        "ab1e8c19e549426d8b4812061659a69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5acde7641f924036ab2e9e3c5744f884",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2875429fb6644e6eaa172d51313b26c4",
            "value": 1
          }
        },
        "42f1cfe6227f45d0b0339a64724c20d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96e13654b5c341308d3ae3b86edee1fd",
            "placeholder": "​",
            "style": "IPY_MODEL_049ff9df15da41969c463515dba07908",
            "value": " 4394/0 [00:00&lt;00:00, 11679.24 examples/s]"
          }
        },
        "1548c4f87e5c4a6c82bde0f2dce9afd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cad8c3d5ab448a8865998908c18485d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906251d9b2ef42a3863030ccbd1038cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5acde7641f924036ab2e9e3c5744f884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2875429fb6644e6eaa172d51313b26c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96e13654b5c341308d3ae3b86edee1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049ff9df15da41969c463515dba07908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}